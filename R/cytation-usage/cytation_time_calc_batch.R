# cytation_time_calc_batch.R
# R script to calculate active scan time from Cytation data audit trail
# Theresa Swayne, 2019-2021
# Reads a folder of TXT files generated by the Data Audit Trail in Gen5 v. 2
# Note -- include only the audit trail. No procedure summary or other info.
# Date and time use the default Gen5 format.

# Caveat -- output contains multiple lines per protocol. Use the last line of each one.
# TODO: eliminate this behavior by truncating the initial timestamp from the text file name

# ---- Setup ----

require(tidyverse) # for reading and parsing
require(tcltk) # for file choosing

# ---- User chooses the input folder ----

logfolder <- tk_choose.dir(default = "", caption = "OPEN the folder with log data") # prompt user

# Get a list of files in the folder

files <- dir(logfolder, pattern = "*.txt") 

# Read the data -- parsing errors may occur but data should be read ok.

mergedDataWithNames <- tibble(filename = files) %>% # column 1 = file names
  mutate(file_contents =
           map(filename,          # column 2 = all the data in the file
               ~ read_csv(file.path(logfolder, .),
                          col_types = cols(Comment = col_character(), 
                                           Date = col_datetime(format = "%m/%d/%Y %H:%M:%S %p")), 
                          skip = 2)))


# make the list into a flat file -- each row contains its source filename

logdata <- unnest(mergedDataWithNames, cols=c(file_contents)) # added in response to 'cols is now required' error


# ---- Find start and end times ----

# remove duplicate lines logged during discontinuous kinetic procedures

logdata_unique <- unique(logdata)

# add a column for the Read number to help with merging the data later 
# read numbers are consecutive through all the log files
 
startTimes <- logdata_unique %>% 
  filter(grepl("started", Event)) %>%
  select(filename, Start = Date)  %>%
  mutate(Read = row_number())

endTimes <- logdata_unique %>% 
  filter(grepl("completed", Event)) %>%
  select(filename, End = Date)  %>%
  mutate(Read = row_number())


# combine start and end times so each row represents a single read step

scanTimes <- full_join(startTimes, endTimes, by = "Read") %>% # combine using original read number
  mutate(filename = filename.x) %>% # get rid of duplicate columns
  select(-c(filename.y, filename.x))

# ---- Calculate elapsed time and save ----

scanTimes <- scanTimes %>% 
  mutate(elapsedTime = difftime(End, Start, units = "hours")) # convert elapsedTime to hours

# filter out NAs that arise from aborted runs
# calculate active time for each experiment (represented by 1 logfile)

scanTimeTotal <-  scanTimes %>%
  group_by(filename) %>%
  filter(is.na(elapsedTime) == FALSE) %>%
  summarise(TotalHours = sum(elapsedTime)) 

# save results in the parent of the log directory 

parentName <- basename(dirname(logfolder)) # name of the log directory without higher levels

parentDir <- dirname(logfolder) # parent of the log directory

outputFile = paste(Sys.Date(), basename(logfolder), "_totals.csv") # spaces will be inserted

write_csv(scanTimeTotal,file.path(parentDir, outputFile))

